# BronchoTransformer: Sequential Vision Transformer for 7-DoF Pose Estimation

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![License](https://img.shields.io/badge/license-MIT-green)

Este repositorio contiene la implementaci√≥n oficial de **BronchoTransformer**, una arquitectura basada en **Vision Transformers (ViT) Secuenciales** dise√±ada para la estimaci√≥n de pose en broncoscopia virtual.

A diferencia de los m√©todos tradicionales que utilizan redes recurrentes (RNNs) o restricciones geom√©tricas expl√≠citas, este modelo aprende dependencias temporales globales directamente de secuencias de video, logrando una **precisi√≥n de localizaci√≥n superior (3.12 mm)** y una mayor estabilidad sin necesidad de sensores externos.

---

## üìã Tabla de Contenidos
- [Introducci√≥n](#introducci√≥n)
- [Preparaci√≥n del Dataset](#preparaci√≥n-del-dataset)
- [Instalaci√≥n](#instalaci√≥n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Uso](#uso)
  - [Entrenamiento](#entrenamiento)
  - [Evaluaci√≥n](#evaluaci√≥n)
- [Resultados](#resultados)
- [Referencias](#referencias)

---

## Introducci√≥n

El objetivo de este proyecto es estimar la pose de la c√°mara (Posici√≥n $x,y,z$ y Orientaci√≥n $q_w, q_x, q_y, q_z$) dentro del √°rbol bronquial utilizando √∫nicamente informaci√≥n visual.

El modelo utiliza un enfoque **End-to-End**:
1.  **Extractor Espacial:** Un ViT procesa cada *frame* individualmente.
2.  **Codificador Temporal:** Un Transformer Encoder modela la secuencia de movimiento.
3.  **Cabezal de Regresi√≥n:** Predice el vector de pose de 7 grados de libertad (7-DoF).

Para probar el modelo, es necesario descargar el dataset sint√©tico del paper **BronchoPose** de Borrego et al. Puedes obtenerlo aqu√≠:
[Descargar Dataset BronchoPose](https://dataverse.csuc.cat/dataset.xhtml?persistentId=doi:10.34810/data2251)

---

## Preparaci√≥n del Dataset

El modelo espera una estructura de directorios espec√≠fica basada en el dataset *VirtualNavigations*.

1.  **Descarga:** Baja los archivos del dataset desde el enlace superior. Nota que llegan en *split zips* (partes divididas).
2.  **Descompresi√≥n:** Une los archivos zip para extraer el contenido completo.
3.  **Organizaci√≥n:**
    * Crea una carpeta llamada `data` en la ra√≠z de este repositorio.
    * Mueve la carpeta descomprimida `VirtualNavigations` dentro de `data`.
    
La estructura final debe verse as√≠:
```text
BronchoTransformer/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ VirtualNavigations/
‚îÇ       ‚îú‚îÄ‚îÄ LENS_P1_14_01_2016_INSP_CPAP/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ Frames/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ P1_r1_to_3.csv
‚îÇ       ‚îú‚îÄ‚îÄ ...
```
## Preparaci√≥n del Dataset
1. Clonar el repositorio:
git clone [https://github.com/tu-usuario/BronchoTransformer.git](https://github.com/tu-usuario/BronchoTransformer.git)
cd BronchoTransformer
2. Instalar dependencias: Se recomienda usar un entorno virtual (conda o venv). Ejecuta el siguiente comando para instalar las librer√≠as necesarias:
pip install torch torchvision timm numpy pandas matplotlib opencv-python tqdm

## Estructura del proyecto
